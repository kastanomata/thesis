\chapter{Conclusioni}

Giunti al termine del progetto, la percezione è di aver appena toccato la superficie. Gli argomenti trattati sono stati numerosi, ma allo stesso tempo abbiamo rilevato numerosi contesti in cui un analisi più approfondita ci permetterebbe di raggiungere una maggiore consapevolezza sul ruolo dei gestori dinamici di memoria nei sistemi operativi moderni. È stata costruita una base teorica solida per la nostra analisi e alcuni punti chiave da considerare quando ci si interroga sull'efficienza degli allocatori di memoria sono stati stabiliti.

Speriamo di essere stati in grado di sottolineare, durante il progetto, l'importanza del dedicare tempo e risorse alla scelta dell'algoritmo di allocazione di memoria più appropriato per le proprie necessità. Soprattutto durante lo sviluppo dei sistemi operativi, fare scelte oculate per quanto riguarda la gestione delle risorse può avere effetti che riverberano per l'efficienza di tutto il calcolatore. È stato fatto un tentativo di dimostrare che l’allocazione dinamica di memoria non deve essere considerata in tutti i casi imprevedibile e per questo inaffidabile: non è necessario che i programmi utilizzino necessariamente l'allocazione statica di memoria quando è richiesto di ottenere determinati risultati.

Con la nostra breve indagine sulla letteratura sull’argomento, alcune risorse che ci sono risultate utili per delineare un percorso didattico sono state menzionate: siamo consapevoli tuttavia che esistano numerose fonti che non abbiamo avuto modo e tempo di vagliare approfonditamente. Abbiamo descritto la specifica implementazione da noi sviluppata, evidenziando i pro e contro delle scelte implementative e le motivazioni alla base dell’adozione di determinati paradigmi. 

In contesti \textit{bare metal} e quindi in assenza di un sistema operativo, dove l'utente deve quindi gestire autonomamente questa risorsa, implementare un allocatore adatto ai propri scopi è sicuramente un'alternativa valida e non da trascurarsi. Sono state verificate in modo pratico le assunzioni teoriche che la nostra indagine suggeriva, e abbiamo delineato grossolanamente alcune strutture che potrebbero essere usate per descrivere i benchmark a cui sottoporre i propri applicativi. Dedicare tempo all'analisi delle prestazioni del proprio programma utilizzando strumenti di varia natura può rivelare possibili congestioni e strade per rendere il proprio programma più efficiente: chiaramente, poiché le riflessioni non sono volte specificatamente a un singolo campo di applicazione, non abbiamo potuto trarre conclusioni approfondite. Tuttavia, è sicuramente possibile basandosi sui dati emersi descrivere un quadro complesso e confermare l'importanza di continuare questa analisi con ulteriori accertamenti. 
 

\section{Aree di ricerca ulteriori}

I risultati ottenuti aprono la strada a ulteriori esperimenti e ottimizzazioni, come l’integrazione di politiche adattive per scenari real-time o l'introduzione di sistemi che garantiscano la \textit{thread safety}. L'aver stabilito l'interfaccia \texttt{Allocator} permetterebbe con facilità di estendere gli strumenti da noi creati per supportare una grande varietà di memory allocators che adottino politiche e meccanismi diversi, per indagare gli effetti delle differenze nell'approccio. allo stesso modo, sicuramente meriterebbe attenzione la semplificazione e lo streamlining delle infrastrutture per il logging. In questo modo potremmo essere più vicini ad ottenere risultati che non ci permettano unicamente di fare un'analisi comparata ma anche di valutare dal punto di vista pratico le capacità dei memory allocators escludendo l'overhead eccessivo che osserviamo in questo momento.

\paragraph{Deferred coalescing.}
Un'area promettente per ottimizzazioni future riguarda l'implementazione di tecniche di \textit{deferred coalescing}, una pratica che consiste nel posticipare l'unione di blocchi liberi adiacenti a momenti strategici invece di essere eseguita immediatamente dopo ogni operazione di rilascio. Questo approccio potrebbe ridurre l'overhead nelle operazioni di deallocazione frequenti, specialmente in scenari dove la frammentazione temporanea è accettabile. La sfida principale consiste nel determinare il momento ottimale per attivare il coalescing e nel bilanciare il trade-off tra memoria immediatamente disponibile e frammentazione accumulata.

\paragraph{Analisi della località dei dati.}
sull'accesso ai dati allocati. Analizzare la località spaziale permetterebbe di comprendere come la disposizione dei blocchi di memoria influisca sull'efficienza della cache, mentre uno studio della località temporale aiuterebbe a valutare la frequenza di riutilizzo dei blocchi e la durata delle allocazioni. Questi dati potrebbero essere utilizzati per ottimizzare le strategie di allocazione, ad esempio raggruppando oggetti con pattern di accesso simili o adottando politiche di placement che minimizzino i cache miss. Un'analisi approfondita della località, supportata da strumenti di profiling, potrebbe quindi fornire indicazioni preziose per migliorare ulteriormente le prestazioni degli allocatori in scenari reali.

\paragraph{Raccolta di traces reali.}
Per validare ulteriormente i risultati ottenuti, sarebbe estremamente utile raccogliere e analizzare trace reali provenienti da applicazioni di produzione in diversi domini (sistemi embedded, server ad alte prestazioni, applicazioni desktop). Questi dataset consentirebbero di testare gli allocatori in condizioni realistiche e variegate, identificando punti di forza e debolezza in scenari complessi che difficilmente possono essere riprodotti con benchmark sintetici. La creazione di una suite standardizzata di trace rappresentative potrebbe inoltre diventare un prezioso strumento per la comunità, facilitando confronti oggettivi tra diverse implementazioni di allocatori.
